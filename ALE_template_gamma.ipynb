{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b859e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import math\n",
    "import scipy\n",
    "import requests\n",
    "import warnings\n",
    "import h5py\n",
    "import fsspec\n",
    "from pyproj import Proj, CRS\n",
    "import pysolid\n",
    "import pymap3d as pm   #for transformation between ENU and llh\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from isce3.core import Ellipsoid as ellips\n",
    "\n",
    "from osgeo import gdal, osr\n",
    "\n",
    "import shapely.wkt as wkt\n",
    "from shapely import geometry\n",
    "\n",
    "from src.ALE_utils import oversample_slc, get_snr_peak, findCR, en2rdr\n",
    "import os\n",
    "import timeit\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d734b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start runtime evaluation\n",
    "start = timeit.default_timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c51546",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters for papermill\n",
    "cslc_url = 's3://opera-pst-rs-pop1/products/CSLC_S1/OPERA_L2_CSLC-S1A_IW_T064-135523-IW2_VV_20220817T015056Z_v0.0_20230527T133501Z/OPERA_L2_CSLC-S1A_IW_T064-135523-IW2_VV_20220817T015056Z_v0.0_20230527T133501Z.h5'\n",
    "cslc_static_url = 's3://opera-pst-rs-pop1/products/CSLC_S1/OPERA_L2_CSLC-S1A_IW_T064-135523-IW2_VV_20220817T015056Z_v0.0_20230527T133501Z_static_layers/OPERA_L2_CSLC-S1A_IW_T064-135523-IW2_VV_20220817T015056Z_v0.0_20230527T133501Z_static_layers.h5'\n",
    "save_dir = 'Rosamond'\n",
    "burst_id = 't064_135523_iw2'\n",
    "date = '20220817'\n",
    "snr_threshold = 15\n",
    "solidtide = 'True'\n",
    "cr_network = 'Rosamond'\n",
    "ovsFactor = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8621bebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pol = 'VV'\n",
    "s3f = fsspec.open(cslc_url, mode='rb', anon=True, default_fill_cache=False)\n",
    "\n",
    "# Load the CSLC and necessary metadata\n",
    "DATA_ROOT = 'science/SENTINEL1'\n",
    "grid_path = f'{DATA_ROOT}/CSLC/grids'\n",
    "static_grid_path = f'{DATA_ROOT}/CSLC/grids/static_layers'\n",
    "metadata_path = f'metadata'\n",
    "burstmetadata_path = f'{DATA_ROOT}/CSLC/metadata/processing_information/s1_burst_metadata'\n",
    "id_path = f'{DATA_ROOT}/identification'\n",
    "\n",
    "with h5py.File(s3f.open(),'r') as h5:\n",
    "    cslc = h5[f'{grid_path}/{pol}'][:]\n",
    "    xcoor = h5[f'{grid_path}/x_coordinates'][:]\n",
    "    ycoor = h5[f'{grid_path}/y_coordinates'][:]\n",
    "    dx = h5[f'{grid_path}/x_spacing'][()].astype(int)\n",
    "    dy = h5[f'{grid_path}/y_spacing'][()].astype(int)\n",
    "    epsg = h5[f'{grid_path}/projection'][()].astype(int)\n",
    "    sensing_start = h5[f'{burstmetadata_path}/sensing_start'][()].astype(str)\n",
    "    sensing_stop = h5[f'{burstmetadata_path}/sensing_stop'][()].astype(str)\n",
    "    dims = h5[f'{burstmetadata_path}/shape'][:]\n",
    "    bounding_polygon = h5[f'{id_path}/bounding_polygon'][()].astype(str) \n",
    "    orbit_direction = h5[f'{id_path}/orbit_pass_direction'][()].astype(str)\n",
    "    center_lon, center_lat = h5[f'{burstmetadata_path}/center']\n",
    "    \n",
    "# Get bounding box\n",
    "cslc_poly = wkt.loads(bounding_polygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb5fcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the CR data already exists\n",
    "if os.path.exists(f'{save_dir}/crdata/crdata_{date}.csv') == False and cr_network=='Rosamond':\n",
    "    # Get the cslc date\n",
    "    date_ = dt.datetime.strptime(sensing_start.astype(str),'%Y-%m-%d %H:%M:%S.%f').strftime('%Y-%m-%d+%H\\u0021%M')\n",
    "\n",
    "    # Download corner reflector data from UAVSAR/NISAR based on the date of the CSLC product\n",
    "    res = requests.get(f'https://uavsar.jpl.nasa.gov/cgi-bin/corner-reflectors.pl?date={str(date_)}&project=uavsar')\n",
    "    open(f'{save_dir}/crdata/crdata_{date}.csv', 'wb').write(res.content)\n",
    "\n",
    "elif os.path.exists(f'{save_dir}/crdata/crdata_{date}.csv') == False and cr_network=='Oklahoma':\n",
    "    # Get the cslc date\n",
    "    date_ = dt.datetime.strptime(sensing_start.astype(str),'%Y-%m-%d %H:%M:%S.%f').strftime('%Y-%m-%d+%H\\u0021%M')\n",
    "    \n",
    "    # Download corner reflector data from UAVSAR/NISAR based on the date of the CSLC product\n",
    "    res = requests.get(f'https://uavsar.jpl.nasa.gov/cgi-bin/corner-reflectors.pl?date={str(date_)}&project=nisar')\n",
    "    open(f'{save_dir}/crdata/crdata_{date}.csv', 'wb').write(res.content)\n",
    "\n",
    "elif os.path.exists(f'{save_dir}/crdata/crdata_{date}.csv') == False and cr_network=='Alaska':\n",
    "    # Get the cslc date\n",
    "    date_ = dt.datetime.strptime(sensing_start.astype(str),'%Y-%m-%d %H:%M:%S.%f').strftime('%Y-%m-%d+%H\\u0021%M')\n",
    "\n",
    "    # Download corner reflector data from NISAR based on the date of the CSLC product\n",
    "    res = requests.get(f'https://uavsar.jpl.nasa.gov/cgi-bin/corner-reflectors.pl?date={str(date_)}&project=alaska')\n",
    "    open(f'crdata_{date}.csv', 'wb').write(res.content)\n",
    "\n",
    "else:\n",
    "    print(f'Corner Reflector Data: crdata_{date}.csv already exists. Skipping download.')\n",
    "\n",
    "# Read to pandas dataframe and rename columns\n",
    "df = pd.read_csv(f'{save_dir}/crdata/crdata_{date}.csv')\n",
    "df.rename(columns={'Corner reflector ID':'ID'}, inplace=True)\n",
    "df.rename(columns={'Latitude (deg)':'lat'}, inplace=True) \n",
    "df.rename(columns={'Longitude (deg)':'lon'}, inplace=True) \n",
    "df.rename(columns={'Azimuth (deg)':'azm'}, inplace=True)\n",
    "df.rename(columns={'Tilt / Elevation angle (deg)':'tilt'}, inplace=True)\n",
    "df.rename(columns={'Height above ellipsoid (m)':'hgt'}, inplace=True) \n",
    "df.rename(columns={'Side length (m)':'slen'}, inplace=True)\n",
    "df.slen = np.round(df.slen,1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed9b626",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (solidtide == 'True' ):\n",
    "    #solid earth tide correction with PySolid\n",
    "    dateformat = '%Y-%m-%d %H:%M:%S.%f'  #date format of input azimuth time\n",
    "    dt0 = dt.datetime.strptime(sensing_start,dateformat)\n",
    "    dt1 = dt.datetime.strptime(sensing_stop,dateformat)\n",
    "    step_sec = 5                        # sample spacing in time domain in seconds\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "\n",
    "        llh = [np.deg2rad(row['lon']), np.deg2rad(row['lat']), row['hgt']]  #lon/lat/hgt\n",
    "\n",
    "        _elp = ellips()\n",
    "        xyz = _elp.lon_lat_to_xyz(llh) #xyz coordinate of CR\n",
    "\n",
    "        # compute SET via pysolid\n",
    "        (dt_out,\n",
    "         tide_e,\n",
    "         tide_n,\n",
    "         tide_u) = pysolid.calc_solid_earth_tides_point(np.rad2deg(llh[1]), np.rad2deg(llh[0]), dt0, dt1,\n",
    "                                                    step_sec=step_sec,\n",
    "                                                    display=False,\n",
    "                                                    verbose=False)\n",
    "\n",
    "        tide_e = np.mean(tide_e[0:2])\n",
    "        tide_n = np.mean(tide_n[0:2])\n",
    "        tide_u = np.mean(tide_u[0:2])\n",
    "\n",
    "        #updating lat,lon,hgt after SET correction\n",
    "        llh = pm.enu2geodetic(tide_e, tide_n, tide_u,np.rad2deg(llh[1]),np.rad2deg(llh[0]),llh[2],deg=True)\n",
    "\n",
    "        df.loc[idx,'lat'] = llh[0]\n",
    "        df.loc[idx,'lon'] = llh[1]\n",
    "        df.loc[idx,'hgt'] = llh[2]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf487c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'lon' not in df.keys():\n",
    "    raise SystemExit('No CRs found within burst, exit notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb97d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the locations of CRs in SAR image\n",
    "UTMx = []\n",
    "UTMy = []\n",
    "xloc = []\n",
    "yloc = []\n",
    "xloc_float = []\n",
    "yloc_float = []\n",
    "_in = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    \n",
    "    _Proj = Proj(CRS.from_epsg(epsg))\n",
    "    _x, _y = _Proj(row['lon'], row['lat'],inverse=False)     #conversion of lat/lon of CRs to UTM coordinates\n",
    "    \n",
    "    #location of CRs in SLC image\n",
    "    _xloc = int((_x-xcoor[0])/dx)    \n",
    "    _yloc = int((_y-ycoor[0])/dy)\n",
    "    \n",
    "    UTMx.append(_x) \n",
    "    UTMy.append(_y)\n",
    "    xloc.append(_xloc)\n",
    "    yloc.append(_yloc)\n",
    "    xloc_float.append((_x-xcoor[0])/dx)\n",
    "    yloc_float.append((_y-ycoor[0])/dy)\n",
    "    _in.append(cslc_poly.contains(geometry.Point(row['lon'], row['lat'])))\n",
    "    \n",
    "df['UTMx'] = UTMx\n",
    "df['UTMy'] = UTMy\n",
    "df['xloc'] = xloc\n",
    "df['yloc'] = yloc\n",
    "df['xloc_float'] = xloc_float\n",
    "df['yloc_float'] = yloc_float\n",
    "df['inPoly'] = _in\n",
    "\n",
    "#checking whether CRs are in SLC coverage. Including only CRs within SLC image\n",
    "df = df[df['inPoly']==True]\n",
    "df.drop('inPoly', axis=1, inplace=True)\n",
    "df = df.reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6522a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select CRs according to orbit direction\n",
    "if cr_network=='Rosamond' or cr_network=='Oklahoma':\n",
    "    if orbit_direction == 'Ascending':\n",
    "        df_filter = df[(df['azm']>140) & (df['azm']<220)].reset_index(drop=True)\n",
    "        #only west-looking CRs (for right-looking ascending)\n",
    "    else:     #Descending\n",
    "        df_filter = df[~((df['azm']>140) & (df['azm']<220))].reset_index(drop=True)\n",
    "        #only east-looking CRs (for right-looking descending)\n",
    "if cr_network=='Alaska':\n",
    "    if orbit_direction == 'Ascending':\n",
    "        # only west-looking CRs (for right-looking ascending)\n",
    "        df_filter = df.loc[(df['azm']>160) & (df['azm']<200)]\n",
    "        # reject N32A if data from past 20220601 as it got overturned\n",
    "        if dt.datetime.strptime('20220601', '%Y%m%d') <= dt.datetime.strptime(str(date), '%Y%m%d'):\n",
    "            df_filter = df_filter[df_filter['ID']!='N32A'].reset_index(drop=True)\n",
    "    else:     #Descending\n",
    "        # only east-looking CRs (for right-looking descending)\n",
    "        df_filter = df[df['azm']<20].reset_index(drop=True)\n",
    "\n",
    "df_filter = df_filter.loc[df_filter['slen']>0.8].reset_index(drop=True)   #excluding SWOT CRs (0.7 m as a side length)\n",
    "df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002f6ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying SLC image\n",
    "buffer = 50\n",
    "minX = df_filter['xloc'].min() - buffer\n",
    "maxX = df_filter['xloc'].max() + buffer\n",
    "minY = df_filter['yloc'].min() - buffer\n",
    "maxY = df_filter['yloc'].max() + buffer\n",
    "\n",
    "scale_ = 1.0\n",
    "exp_ = 0.15\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 3))\n",
    "cax=ax.imshow(scale_*(np.abs(cslc))**exp_, cmap='gray',interpolation=None, origin='upper')\n",
    "ax.set_xlim(minX,maxX)\n",
    "ax.set_ylim(minY,maxY)\n",
    "\n",
    "for sl in pd.unique(df_filter.slen):\n",
    "    xx = df_filter.loc[df_filter['slen']==sl]['xloc']\n",
    "    yy = df_filter.loc[df_filter['slen']==sl]['yloc']\n",
    "    ID = df_filter.loc[df_filter['slen']==sl]['ID']\n",
    "    \n",
    "    if sl == 2.4:\n",
    "        color='blue'\n",
    "    elif sl == 4.8:\n",
    "        color='red'\n",
    "    elif sl == 2.8:\n",
    "        color='yellow'\n",
    "    else:\n",
    "        color='green'\n",
    "    \n",
    "    ax.scatter(xx,yy,color=color,marker=\"+\",lw=1)\n",
    "    for _ID,_xx,_yy in zip(ID,xx,yy):\n",
    "        ax.annotate(_ID, (_xx, _yy), fontsize=10)\n",
    "\n",
    "ax.set_aspect(1)\n",
    "fig.suptitle(f'{cr_network}_{burst_id}_{date}')\n",
    "fig.savefig(f'{save_dir}/pngs/S1_CSLC_CRs_{cr_network}_{burst_id}_{date}.png',dpi=300,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0850e979",
   "metadata": {},
   "outputs": [],
   "source": [
    "xpeak = []\n",
    "ypeak = []\n",
    "snr = []\n",
    "\n",
    "for ID, xoff, yoff in zip(df_filter['ID'],df_filter['xloc'],df_filter['yloc']):\n",
    "    # crop a patch of 10*10 with center at the calculated CR position\n",
    "    pxbuff = 5\n",
    "    pybuff = 5\n",
    "    cropcslc = cslc[(yoff-pybuff):(yoff+pybuff),(xoff-pxbuff):(xoff+pxbuff)]\n",
    "    _snr = get_snr_peak(cropcslc)\n",
    "\n",
    "    # find the peak amplitude in the 10*10 patch\n",
    "    yind,xind = np.unravel_index(np.argmax(np.abs(cropcslc), axis=None), cropcslc.shape)\n",
    "    \n",
    "    # give a warning if the peak and the calculated postion are too far\n",
    "    dyind = yind-pybuff; dxind = xind-pxbuff\n",
    "    dist = math.sqrt(dyind**2+dxind**2)\n",
    "    if dist > 5.0:\n",
    "        warnings.warn(f'the most bright pixel and the xloc is too far for CR {ID}')\n",
    "    \n",
    "    # crop a patch of 32*32 but with its center at the peak\n",
    "    xbuff = 32\n",
    "    ybuff = 32\n",
    "    ycrop = np.arange(yoff+dyind-ybuff,yoff+dyind+ybuff)\n",
    "    xcrop = np.arange(xoff+dxind-xbuff,xoff+dxind+xbuff)\n",
    "    cropcslc = cslc[ycrop,:][:,xcrop]\n",
    "\n",
    "    # Oversample slc\n",
    "    cropcslc_ovs,ycrop_ovs,xcrop_ovs = oversample_slc(cropcslc,sampling=ovsFactor,y=ycrop,x=xcrop)\n",
    "\n",
    "    # find the peak amplitude again in a 2 x 2 patch, it correspond to \n",
    "    # (2*ovsFactor) x (2*ovsFactor) in oversampled slc\n",
    "    yoff2 = int(cropcslc_ovs.shape[0]/2)\n",
    "    xoff2 = int(cropcslc_ovs.shape[1]/2)\n",
    "    cropcslc2 = cropcslc_ovs[yoff2-ovsFactor:yoff2+ovsFactor+1,\n",
    "                           xoff2-ovsFactor:xoff2+ovsFactor+1]\n",
    "    yind2,xind2 = np.unravel_index(np.argmax(abs(cropcslc2), axis=None), cropcslc2.shape)\n",
    "    dyind2 = yind2-ovsFactor; dxind2 = xind2-ovsFactor\n",
    "\n",
    "    # crop a patch of 3x3 oversampled patch with center at the peak\n",
    "    cropcslc2 = cropcslc_ovs[yoff2+dyind2-1:yoff2+dyind2+2,xoff2+dxind2-1:xoff2+dxind2+2]\n",
    "    ycrop2 = ycrop_ovs[yoff2+dyind2-1:yoff2+dyind2+2]\n",
    "    xcrop2 = xcrop_ovs[xoff2+dxind2-1:xoff2+dxind2+2]\n",
    "    xxcrop2,yycrop2 = np.meshgrid(xcrop2,ycrop2)\n",
    "    xxcrop2_f = xxcrop2.flatten()\n",
    "    yycrop2_f = yycrop2.flatten()\n",
    "    cropcslc2_f = cropcslc2.flatten()\n",
    "\n",
    "    # Check if pixel values in a patch are non-NaN\n",
    "    valid = ~(np.isnan(cropcslc2_f))\n",
    "    count_valid = np.count_nonzero(valid)\n",
    "\n",
    "    if count_valid == 0:\n",
    "        _ypeak, _xpeak = [np.nan, np.nan]\n",
    "\n",
    "    else:\n",
    "        _ypeak,_xpeak = findCR(np.abs(cropcslc2_f[valid]),yycrop2_f[valid],xxcrop2_f[valid],\n",
    "                            x_bound=[xcrop2[0],xcrop2[-1]],y_bound=[ycrop2[0],ycrop2[-1]],method=\"para\")\n",
    "\n",
    "    xpeak.append(_xpeak)\n",
    "    ypeak.append(_ypeak)\n",
    "    snr.append(_snr)\n",
    "    \n",
    "df_filter['xloc_CR'] = xpeak\n",
    "df_filter['yloc_CR'] = ypeak\n",
    "df_filter['snr'] = snr\n",
    "df_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be13be5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter = df_filter.dropna()\n",
    "df_filter = df_filter[df_filter.snr > snr_threshold]\n",
    "df_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df38707d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get static layers\n",
    "s3f = fsspec.open(cslc_static_url, mode='rb', anon=True, default_fill_cache=False)\n",
    "\n",
    "with h5py.File(s3f.open(),'r') as h5:\n",
    "    incidence_angle = h5[f'{static_grid_path}/incidence'][:]\n",
    "    azimuth_angle = h5[f'{static_grid_path}/heading'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503c38f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# absolute geolocation error in Easting and Northing directions \n",
    "ALE_EW = (df_filter['xloc_CR'] -  df_filter['xloc_float'])*dx\n",
    "ALE_NS = (df_filter['yloc_CR'] - df_filter['yloc_float'])*np.abs(dy)\n",
    "\n",
    "# Convert to ground range and azimuth offsets\n",
    "ALE_Rg, ALE_Az = en2rdr(ALE_EW, ALE_NS, azimuth_angle[df_filter['yloc'], df_filter['xloc']], incidence_angle[df_filter['yloc'], df_filter['xloc']])\n",
    "\n",
    "# Add to the dataframe\n",
    "df_filter.loc[:,\"azi_angle\"] = azimuth_angle[df_filter['yloc'], df_filter['xloc']]\n",
    "df_filter.loc[:,\"inc_angle\"] = incidence_angle[df_filter['yloc'], df_filter['xloc']]\n",
    "df_filter.loc[:,\"ALE_EW\"] = ALE_EW\n",
    "df_filter.loc[:,\"ALE_NS\"] = ALE_NS\n",
    "df_filter.loc[:,\"ALE_Rg\"] = ALE_Rg\n",
    "df_filter.loc[:,\"ALE_Az\"] = ALE_Az\n",
    "df_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0ac44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting ALE\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "sc = ax.scatter(df_filter.ALE_EW, df_filter.ALE_NS, s=200, c=df_filter['slen'], alpha=0.8, marker='o')\n",
    "ax.legend(*sc.legend_elements(),facecolor='lightgray')\n",
    "ax.get_legend().set_title('side length (m)')\n",
    "for ii, txt in enumerate(df_filter.ID):\n",
    "    ax.annotate(txt, (df_filter[df_filter['ID']==txt].ALE_EW, df_filter[df_filter['ID']==txt].ALE_NS), color='orange')   #putting IDs in each CR\n",
    "ax.grid(True)\n",
    "ax.set_xlim(-5,5)\n",
    "ax.set_ylim(-5,5)\n",
    "ax.axhline(0, color='black')\n",
    "ax.axvline(0, color='black')\n",
    "ax.set_title(f'$\\Delta x$: {np.round(np.nanmean(ALE_EW), 3)} +/- {np.round(np.nanstd(ALE_EW),3)} m, \\\n",
    "    $\\Delta y$: {np.round(np.nanmean(ALE_NS),3)}, +/- {np.round(np.nanstd(ALE_NS),3)} m')\n",
    "ax.set_xlabel('$\\Delta x$ (m)')\n",
    "ax.set_ylabel('$\\Delta y$ (m)')\n",
    "fig.suptitle(f'Absolute location error for {date} (Eastings vs Northings direction)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da7ad1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting ALE\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "sc = ax.scatter(df_filter.ALE_Rg, df_filter.ALE_Az, s=200, c=df_filter['slen'], alpha=0.8, marker='o')\n",
    "ax.legend(*sc.legend_elements(),facecolor='lightgray')\n",
    "ax.get_legend().set_title('side length (m)')\n",
    "for ii, txt in enumerate(df_filter.ID):\n",
    "    ax.annotate(txt, (df_filter[df_filter['ID']==txt].ALE_Rg, df_filter[df_filter['ID']==txt].ALE_Az), color='orange')   #putting IDs in each CR\n",
    "ax.grid(True)\n",
    "ax.set_xlim(-5,5)\n",
    "ax.set_ylim(-5,5)\n",
    "ax.axhline(0, color='black')\n",
    "ax.axvline(0, color='black')\n",
    "ax.set_title(f'$\\Delta gr$: {np.round(np.nanmean(ALE_Rg), 3)} +/- {np.round(np.nanstd(ALE_Rg),3)} m, \\\n",
    "    $\\Delta az$: {np.round(np.nanmean(ALE_Az),3)}, +/- {np.round(np.nanstd(ALE_Az),3)} m')\n",
    "ax.set_xlabel('Ground range offset (m)')\n",
    "ax.set_ylabel('Azimuth offset (m)')\n",
    "fig.suptitle(f'Absolute location error for {date} (Ground Range vs Azimuth Directions)')\n",
    "fig.savefig(f'{save_dir}/pngs/ALE_{cr_network}_{burst_id}_{date}.png',dpi=300,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5668dd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the summary\n",
    "ALE_EW_Mean = np.round(np.nanmean(ALE_EW),3)\n",
    "ALE_NS_Mean = np.round(np.nanmean(ALE_NS),3)\n",
    "ALE_EW_Stdev = np.round(np.nanstd(ALE_EW),3)\n",
    "ALE_NS_Stdev = np.round(np.nanstd(ALE_NS),3)\n",
    "ALE_Rg_Mean = np.round(np.nanmean(ALE_Rg),3)\n",
    "ALE_Az_Mean = np.round(np.nanmean(ALE_Az),3)\n",
    "ALE_Rg_Stdev = np.round(np.nanstd(ALE_Rg),3)\n",
    "ALE_Az_Stdev = np.round(np.nanstd(ALE_Az),3)\n",
    "\n",
    "summary = []\n",
    "summary.append([date, ALE_EW_Mean, ALE_EW_Stdev, ALE_NS_Mean, ALE_NS_Stdev, ALE_Rg_Mean, ALE_Rg_Stdev, ALE_Az_Mean, ALE_Az_Stdev])\n",
    "summary_df = pd.DataFrame(summary)\n",
    "summary_df.to_csv(f'{save_dir}/summary/ALE_{cr_network}.csv', mode='a', header=False)\n",
    "\n",
    "# Save the entire dataframe to csv\n",
    "df_filter.loc[:,\"Date\"] = [date]* len(df_filter)\n",
    "df_filter.to_csv(f'{save_dir}/summary/ALE_{cr_network}_ID.csv', mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df15c808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# End runtime evaluation\n",
    "stop = timeit.default_timer()\n",
    "print(f'Time: ', (stop - start)/60, 'min.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "calval-CSLC",
   "language": "python",
   "name": "calval-cslc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
